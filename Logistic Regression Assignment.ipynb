{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "3d320cf0-a091-4180-848a-625ce72c6758",
      "cell_type": "code",
      "source": "                                        ### Logistic Regression Assignment ###",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "839d64a4-ef89-40e1-b6e7-4af0d0fbd208",
      "cell_type": "code",
      "source": "### Theoretical Questions\n\n1. What is Logistic Regression, and how does it differ from Linear Regression?\n2. What is the mathematical equation of Logistic Regression?\n3. Why do we use the Sigmoid function in Logistic Regression?\n4. What is the cost function of Logistic Regression?\n5. What is Regularization in Logistic Regression? Why is it needed?\n6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n7. When should we use Elastic Net instead of Lasso or Ridge?\n8. What is the impact of the regularization parameter (1) in Logistic Regression?\n9. What are the key assumptions of Logistic Regression?\n10. What are some alternatives to Logistic Regression for classification tasks?\n11. What are Classification Evaluation Metrics?\n12. How does class imbalance affect Logistic Regression?\n13. What is Hyperparameter Tuning in Logistic Regression?\n14. What are different solvers in Logistic Regression? Which one should be used?\n15. How is Logistic Regression extended for multiclass classification?\n16. What are the advantages and disadvantages of Logistic Regression?\n17. What are some use cases of Logistic Regression?\n18. What is the difference between Softmax Regression and Logistic Regression?\n19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n20. How do we interpret coefficients in Logistic Regression?\n\n### Practical Questions\n\n1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy.\n2. Write a Python program to apply Ll regularization (Lasso) on a dataset using LogisticRegression(penalty='1') and print the model accuracy,\n3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty=12). Print model accuracy and coefficients.\n4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet).\n5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class=ovr\n6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy.\n7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy.\n8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy.\n9. Write a Python program to apply Randomized SearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy.\n10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy.\n11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification.\n12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and FI-Score.\n13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance.\n14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance.\n15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling.\n16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score.\n17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy.\n18. Write a Python program to train Logistic Regression and identify important features based on model coefficients.\n19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen's Kappa Score.\n20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification\n21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, Ibtgs) and compare their accuracy.\n22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC).\n23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling\n24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation.\n25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8c87eb4d-1740-48dd-8269-d9b2a1f7d4a3",
      "cell_type": "code",
      "source": "Answer1:- Logistic Regression is a supervised learning algorithm used for classification tasks. It differs from Linear Regression in that it predicts probabilities instead of continuous values.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "97e14287-7305-4e37-87e8-f06b098e6ef5",
      "cell_type": "code",
      "source": "Answer2:- The mathematical equation of Logistic Regression is given by: p = 1 / (1 + e^(-z)), where p is the probability, e is the base of the natural logarithm, and z is a linear combination of the features.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4ba4ecf2-97b1-441c-9d2d-25d9cd012f75",
      "cell_type": "code",
      "source": "Answer3:- The Sigmoid function is used in Logistic Regression because it maps any real number to a value between 0 and 1, making it suitable for binary classification tasks.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0ce6a7f3-866a-45cf-bdb2-f28904c64b32",
      "cell_type": "code",
      "source": "Answer4:- The cost function of Logistic Regression is the Log Loss function, which measures the difference between the predicted probabilities and the actual labels.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "37c87c99-4546-4bcd-9af4-3b304f730d92",
      "cell_type": "code",
      "source": "Answer5:- Regularization in Logistic Regression is a technique used to prevent overfitting by adding a penalty term to the cost function. It is needed to reduce the complexity of the model and improve its generalization performance.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fc7e410d-56b7-4d1b-81d9-a9686d0840e0",
      "cell_type": "code",
      "source": "Answer6:- Lasso regression uses L1 regularization, Ridge regression uses L2 regularization, and Elastic Net regression uses a combination of both L1 and L2 regularization.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3bf7e363-5247-4101-9dfe-514c846954e7",
      "cell_type": "code",
      "source": "Answer7:- Elastic Net is useful when there are multiple features that are correlated with each other. It can handle both sparse and dense models.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "63304c19-75d3-4654-891e-8e4b3cf3aa57",
      "cell_type": "code",
      "source": "Answer8:- The regularization parameter C controls the strength of the regularization. A small value of C means stronger regularization, while a large value of C means weaker regularization.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bd25d6c9-d69b-40cf-a5a5-ff18e611a6a5",
      "cell_type": "code",
      "source": "Answer9:- The key assumptions of Logistic Regression are independence of observations, linearity of the logit, and absence of multicollinearity.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9a5f4912-bd87-457f-94a2-d47f6d8f676c",
      "cell_type": "code",
      "source": "Answer10:- Some alternatives to Logistic Regression are Decision Trees, Random Forest, Support Vector Machines (SVMs), and Neural Networks.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a677123d-fd6c-47b6-bd84-32b24efccc75",
      "cell_type": "code",
      "source": "Answer11:- Classification Evaluation Metrics include accuracy, precision, recall, F1-score, and ROC-AUC score.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1a800492-74e5-40bf-b327-45e22014ce41",
      "cell_type": "code",
      "source": "Answer12:- Class imbalance can affect Logistic Regression by biasing the model towards the majority class.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7e74b842-b6a9-4232-ac1a-e879515c69d2",
      "cell_type": "code",
      "source": "Answer13:- Hyperparameter Tuning in Logistic Regression involves finding the optimal values of the hyperparameters, such as the regularization parameter C.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5a649f20-9111-4ff3-b5f2-655d1a90771c",
      "cell_type": "code",
      "source": "Answer14:- Some popular solvers for Logistic Regression are liblinear, saga, and lbfgs. The choice of solver depends on the specific problem and dataset.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "93e121be-f811-449e-ac26-9e38e4e61272",
      "cell_type": "code",
      "source": "Answer15:- Logistic Regression can be extended for multiclass classification using techniques such as One-vs-Rest (OvR) and Softmax Regression.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "df41039d-c18f-4169-bdba-239d2f849c37",
      "cell_type": "code",
      "source": "Answer16:- Advantages of Logistic Regression include its simplicity, interpretability, and efficiency. Disadvantages include its assumption of linearity and its sensitivity to outliers.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "38323130-fb9e-4b10-b862-33b8797ed9f9",
      "cell_type": "code",
      "source": "Answer17:- Logistic Regression can be used for credit risk assessment, medical diagnosis, and customer churn prediction.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "196876a1-fbc4-4ca3-b83d-fb86f4b03c34",
      "cell_type": "code",
      "source": "Answer18:- Softmax Regression is an extension of Logistic Regression to multiclass classification problems.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9707eb54-b71e-4d40-a2a9-c987921a0378",
      "cell_type": "code",
      "source": "Answer19:- The choice between OvR and Softmax depends on the specific problem and dataset.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bf55b76f-a154-4e69-a440-b6269dd5f891",
      "cell_type": "code",
      "source": "Answer20:- The coefficients in Logistic Regression represent the change in the log odds of the outcome variable for a one-unit change in the predictor variable.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "17edf7ad-fc70-4220-8429-3f6396292069",
      "cell_type": "code",
      "source": "Answer1:- from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "90096433-1fc1-4a60-86df-409ed1fda664",
      "cell_type": "code",
      "source": "Answer2:- from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(penalty='l1', solver='liblinear')\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3b47534b-992e-4c22-bee9-dffc4596a6ba",
      "cell_type": "code",
      "source": "Answer3:- from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(penalty='l2')\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\nprint(f'Coefficients: {model.coef_}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3a2d899f-77f2-4aca-8b3a-65017d8db706",
      "cell_type": "code",
      "source": "Answer4:- from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e5cdd675-ad21-41da-b98f-94870bed57d3",
      "cell_type": "code",
      "source": "Answer5:- from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(multi_class='ovr')\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d0218316-15c4-4caa-be2b-9a3ea040b08c",
      "cell_type": "code",
      "source": "Answer6:- from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nparam_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\ngrid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\nprint(f'Best parameters: {grid_search.best_params_}')\nprint(f'Best accuracy: {grid_search.best_score_:.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2cd35ced-029a-4c8a-9db4-20ba927083b9",
      "cell_type": "code",
      "source": "Answer7:- from sklearn.datasets import load_iris\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nskf = StratifiedKFold(n_splits=5)\naccuracies = []\n\nfor train_index, test_index in skf.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracies.append(accuracy_score(y_test, y_pred))\n\nprint(f'Average accuracy: {sum(accuracies) / len(accuracies):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ed434220-3fd5-4a9e-ad8a-dfe261909ebe",
      "cell_type": "code",
      "source": "Answer8:- import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\ndf = pd.read_csv('your_dataset.csv')\nX = df.drop('target', axis=1)\ny = df['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2554836b-fc07-4908-ae5d-0ddd06975ff0",
      "cell_type": "code",
      "source": "Answer9:- from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nparam_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\nrandom_search = RandomizedSearchCV(LogisticRegression(), param_grid, cv=5, n_iter=10)\nrandom_search.fit(X_train, y_train)\n\nprint(f'Best parameters: {random_search.best_params_}')\nprint(f'Best accuracy: {random_search.best_score_:.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "aab4c8fa-b39e-4802-ac6f-d1668e666ab0",
      "cell_type": "code",
      "source": "Answer10:- from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = OneVsOneClassifier(LogisticRegression())\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4b9d2ead-a6fe-4895-9021-423546dcd3ab",
      "cell_type": "code",
      "source": "Answer11:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(confusion_matrix(y_test, y_pred))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d9f2c4f6-4c17-4866-a904-dfd4d7a86d96",
      "cell_type": "code",
      "source": "Answer12:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Precision: {precision_score(y_test, y_pred):.2f}')\nprint(f'Recall: {recall_score(y_test, y_pred):.2f}')\nprint(f'F1-Score: {f1_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "293a2c0f-3ee6-463a-8c02-35b65b85586e",
      "cell_type": "code",
      "source": "Answer13:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(class_weight='balanced')\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')\nprint(classification_report(y_test, y_pred))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "32c7377c-43fd-488f-834b-423fc212c86a",
      "cell_type": "code",
      "source": "Answer14:- import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Load Titanic dataset\ndf = pd.read_csv('titanic.csv')\n\n# Preprocess data\ndf = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\ndf['Age'] = df['Age'].fillna(df['Age'].mean())\ndf['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n\nX = df.drop('Survived', axis=1)\ny = df['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "20cafd26-c730-4bee-ac43-af346bacfddc",
      "cell_type": "code",
      "source": "Answer15:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nmodel = LogisticRegression()\nmodel.fit(X_train_scaled, y_train)\n\ny_pred = model.predict(X_test_scaled)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "33b398ce-44c5-4e60-91db-57b477e5a741",
      "cell_type": "code",
      "source": "Answer16:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred_proba = model.predict_proba(X_test)[:, 1]\nprint(f'ROC-AUC score: {roc_auc_score(y_test, y_pred_proba):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1cb48a1e-d170-4620-9a0a-e201a03bb35e",
      "cell_type": "code",
      "source": "Answer17:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression(C=0.5)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e3a9d3e9-e448-4f4e-9aba-d62d7600ef36",
      "cell_type": "code",
      "source": "Answer18:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\nprint(f'Coefficients: {model.coef_}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "32eba5cb-ba3c-43e1-b966-0f1008cb376a",
      "cell_type": "code",
      "source": "Answer19:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import cohen_kappa_score\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Cohen\\'s Kappa score: {cohen_kappa_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e777e3a7-bca4-466e-8730-47dbe90cac0a",
      "cell_type": "code",
      "source": "Answer20:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_curve, auc\nimport matplotlib.pyplot as plt\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred_proba = model.predict_proba(X_test)[:, 1]\nprecision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\nauc_precision_recall = auc(recall, precision)\n\nplt.plot(recall, precision)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.show()\nprint(f'AUC-Precision-Recall: {auc_precision_recall:.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "51ee61f7-bb27-443c-948d-73acb070ddc0",
      "cell_type": "code",
      "source": "Answer21:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nsolvers = ['liblinear', 'saga', 'lbfgs']\nfor solver in solvers:\n    model = LogisticRegression(solver=solver)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(f'Solver: {solver}, Accuracy: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "717aa62d-0ab5-41ca-b667-fa5794905723",
      "cell_type": "code",
      "source": "Answer22:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import matthews_corrcoef\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nprint(f'Matthews Correlation Coefficient: {matthews_corrcoef(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "887c2042-87b4-4793-be4b-5e189ca06b2d",
      "cell_type": "code",
      "source": "Answer23:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Without scaling\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(f'Accuracy without scaling: {accuracy_score(y_test, y_pred):.2f}')\n\n# With scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nmodel = LogisticRegression()\nmodel.fit(X_train_scaled, y_train)\ny_pred = model.predict(X_test_scaled)\nprint(f'Accuracy with scaling: {accuracy_score(y_test, y_pred):.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "62811b95-fd92-45d4-9d19-4a5e5028f1f5",
      "cell_type": "code",
      "source": "Answer24:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nparam_grid = {'C': [0.1, 1, 10]}\ngrid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\n\nprint(f'Best C: {grid_search.best_params_[\"C\"]}')\nprint(f'Best score: {grid_search.best_score_:.2f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "96ab2a72-31a8-416c-a401-3d385cf28afe",
      "cell_type": "code",
      "source": "Answer25:- from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport joblib\n\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\njoblib.dump(model, 'logistic_regression_model.joblib')\n\nloaded_model = joblib.load('logistic_regression_model.joblib')\ny_pred = loaded_model.predict(X_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}